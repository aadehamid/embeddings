{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import (\n",
    "    VectorStoreIndex,\n",
    "    ServiceContext,\n",
    "    StorageContext,\n",
    "    SQLDatabase,\n",
    "    download_loader\n",
    ")\n",
    "from llama_index.vector_stores import WeaviateVectorStore\n",
    "\n",
    "import weaviate\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "import os\n",
    "openai.api_key = os.getenv(\"OPENA_AI_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = weaviate.Client(\n",
    "    embedded_options=weaviate.embedded.EmbeddedOptions()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Schema\n",
    "podcast_schema = {\n",
    "   \"classes\": [\n",
    "       {\n",
    "           \"class\": \"Podcast\",\n",
    "           \"description\": \"Weaviate podcast\",\n",
    "           \"vectorizer\": \"text2vec-openai\",\n",
    "           \"properties\": [\n",
    "               {\n",
    "                  \"name\": \"Content\",\n",
    "                  \"dataType\": [\"text\"],\n",
    "                  \"description\": \"Content from the podcasts.\",\n",
    "               }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "client.schema.create(podcast_schema)\n",
    "print(\"Podcast schema was created.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pkg_resources/_vendor/jaraco/text/__init__.py:593: ResourceWarning: unclosed file <_io.TextIOWrapper name='/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/llama_index/download/llamahub_modules/requirements.txt' mode='r' encoding='UTF-8'>\n",
      "  for item in lines:\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting youtube_transcript_api~=0.5.0 (from -r /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/llama_index/download/llamahub_modules/requirements.txt (line 1))\n",
      "  Downloading youtube_transcript_api-0.5.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from youtube_transcript_api~=0.5.0->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/llama_index/download/llamahub_modules/requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->youtube_transcript_api~=0.5.0->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/llama_index/download/llamahub_modules/requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->youtube_transcript_api~=0.5.0->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/llama_index/download/llamahub_modules/requirements.txt (line 1)) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->youtube_transcript_api~=0.5.0->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/llama_index/download/llamahub_modules/requirements.txt (line 1)) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->youtube_transcript_api~=0.5.0->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/llama_index/download/llamahub_modules/requirements.txt (line 1)) (2023.11.17)\n",
      "Installing collected packages: youtube_transcript_api\n",
      "Successfully installed youtube_transcript_api-0.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/llama_index/download/llamahub_modules/youtube_transcript/base.py:46: DeprecationWarning: invalid escape sequence '\\{'\n",
      "  \"  youtube.com/watch?v=\\{video_id\\} \"\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/llama_index/download/llamahub_modules/youtube_transcript/base.py:48: DeprecationWarning: invalid escape sequence '\\{'\n",
      "  \"  youtube.com/embed?v=\\{video_id\\} \"\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/llama_index/download/llamahub_modules/youtube_transcript/base.py:50: DeprecationWarning: invalid escape sequence '\\}'\n",
      "  \"  youtu.be/{video_id\\} (never includes www subdomain)\"\n"
     ]
    }
   ],
   "source": [
    "from llama_index import download_loader\n",
    "\n",
    "YouTubeTranscriptReader = download_loader(\"YoutubeTranscriptReader\")\n",
    "\n",
    "loader = YouTubeTranscriptReader()\n",
    "podcasts = loader.load_data(ytlinks=['https://www.youtube.com/watch?v=xk28RMhRy1U', 'https://www.youtube.com/watch?v=Du6IphCcCec',\n",
    "'https://www.youtube.com/watch?v=Q7f2JeuMN7E', 'https://www.youtube.com/watch?v=nSCUk5pHXlo'])\n",
    "     \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Weaviate Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"level\":\"info\",\"msg\":\"Created shard podcasts_index_node_gpp1dwwWJZH8 in 1.837564ms\",\"time\":\"2024-01-28T01:01:17Z\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-28T01:01:17Z\",\"took\":103196}\n"
     ]
    }
   ],
   "source": [
    "vector_store = WeaviateVectorStore(weaviate_client=client, class_prefix=\"Podcasts_index\")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "\n",
    "podcast_index = VectorStoreIndex.from_documents(podcasts, storage_context=storage_context)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SQL Table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import (\n",
    "    create_engine,\n",
    "    MetaData,\n",
    "    Table,\n",
    "    Column,\n",
    "    String,\n",
    "    Integer,\n",
    "    select,\n",
    "    column,\n",
    ")\n",
    "\n",
    "engine = create_engine(\"sqlite:///:memory:\", future=True)\n",
    "metadata_obj = MetaData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"podcast_stats\"\n",
    "podcast_stats_table = Table(\n",
    "    table_name,\n",
    "    metadata_obj,\n",
    "    Column(\"podcast_title\", String(16), primary_key=True),\n",
    "    Column(\"views\", Integer),\n",
    "    Column(\"duration\", Integer),\n",
    ")\n",
    "\n",
    "metadata_obj.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['podcast_stats'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "metadata_obj.tables.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import insert\n",
    "\n",
    "rows = [\n",
    "    {\"podcast_title\": \"Weaviate 1.20\", \"views\": 328, \"duration\": 65},\n",
    "    {\"podcast_title\": \"Weaviate 1.19\", \"views\": 280, \"duration\": 27},\n",
    "    {\"podcast_title\": \"Weaviate 1.18\", \"views\": 428, \"duration\": 65},\n",
    "    {\"podcast_title\": \"Weaviate 1.17\", \"views\": 257, \"duration\": 43}\n",
    "]\n",
    "\n",
    "for row in rows:\n",
    "  stmt = insert(podcast_stats_table).values(**row)\n",
    "  with engine.connect() as connection:\n",
    "    cursor = connection.execute(stmt)\n",
    "    connection.commit()\n",
    "     \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SQL Table in Llamaindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_database = SQLDatabase(engine, include_tables=[\"podcast_stats\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.indices.struct_store.sql_query import NLSQLTableQueryEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up text2SQL prompt\n",
    "sql_query_engine = NLSQLTableQueryEngine(\n",
    "    sql_database=sql_database,\n",
    "    tables=[\"podcast_stats\"],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vector_query_engine = podcast_index.as_query_engine()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tell LlamaIndex about the Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.query_engine import QueryEngineTool\n",
    "\n",
    "sql_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine = sql_query_engine,\n",
    "    description=(\n",
    "        \"Useful for translating a natural language query into a SQL query over a table containing: \"\n",
    "        \"podcast_stats, containing the views/duration of each podcast\"\n",
    "    ),\n",
    ")\n",
    "vector_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=vector_query_engine,\n",
    "    description=\"Useful for answering semantic questions about Weaviate release podcasts\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.query_engine.router_query_engine import RouterQueryEngine\n",
    "from llama_index.selectors.llm_selectors import LLMSingleSelector\n",
    "\n",
    "query_engine = RouterQueryEngine(\n",
    "    selector=LLMSingleSelector.from_defaults(),\n",
    "    query_engine_tools=([sql_tool] + [vector_tool]),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The podcast episode titled \"Weaviate 1.18\" had the most views, with a total of 428 views.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = query_engine.query(\"Which release podcast had the most views?\")\n",
    "print(str(response))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A new feature in Weaviate is multi-tenancy. This feature allows users to separate and isolate their data from other users within the application. For example, if you have an app that allows you to index documents from your hard drive, you can use multi-tenancy to ensure that only you can search through your documents and not other users. This feature is particularly useful in the context of Vector search, as it helps to limit the vector space and improve search efficiency. Without multi-tenancy, the graph containing billions of vectors would need to be cut into smaller chunks for each user, resulting in potential disconnections or inefficient traversal. Multi-tenancy in Weaviate addresses this technical requirement and provides a solution for efficient and isolated data management.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"level\":\"info\",\"msg\":\"Created shard blogpost_aoHZA7ipG29I in 1.177625ms\",\"time\":\"2024-01-28T01:28:38Z\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-28T01:28:38Z\",\"took\":96751}\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Tell me about a new feature in Weaviate\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
