{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.indices.vector_store.base import VectorStoreIndex\n",
    "from llama_index.readers.file.base import SimpleDirectoryReader\n",
    "\n",
    "# Needed for running async functions in Jupyter Notebook\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-01-28 01:52:35--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 75042 (73K) [text/plain]\n",
      "Saving to: ‘data/paul_graham/paul_graham_essay.txt’\n",
      "\n",
      "data/paul_graham/pa 100%[===================>]  73.28K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2024-01-28 01:52:35 (71.9 MB/s) - ‘data/paul_graham/paul_graham_essay.txt’ saved [75042/75042]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p 'data/paul_graham/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "query = \"What did the author do growing up?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The author, growing up, worked on writing and programming. They wrote short stories and tried writing programs on \n",
       "an IBM <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1401</span> computer. They later got a microcomputer and started programming more extensively, writing simple games\n",
       "and a word processor.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The author, growing up, worked on writing and programming. They wrote short stories and tried writing programs on \n",
       "an IBM \u001b[1;36m1401\u001b[0m computer. They later got a microcomputer and started programming more extensively, writing simple games\n",
       "and a word processor.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_query_engine = index.as_query_engine()\n",
    "response = base_query_engine.query(query)\n",
    "rprint(response.response)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R## etry Query Engine\n",
    "The retry query engine uses an evaluator to improve the response from a base query engine.\n",
    "\n",
    "It does the following:\n",
    "\n",
    "1. first queries the base query engine, then\n",
    "\n",
    "2. use the evaluator to decided if the response passes.\n",
    "\n",
    "3. If the response passes, then return response,\n",
    "\n",
    "4. Otherwise, transform the original query with the evaluation result (query, response, and feedback) into a new query,\n",
    "\n",
    "5. Repeat up to max_retries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The author, growing up, worked on writing and programming. They wrote short stories and tried writing programs on \n",
       "an IBM <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1401</span> computer. They later got a microcomputer and started programming more extensively, writing simple games\n",
       "and a word processor.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The author, growing up, worked on writing and programming. They wrote short stories and tried writing programs on \n",
       "an IBM \u001b[1;36m1401\u001b[0m computer. They later got a microcomputer and started programming more extensively, writing simple games\n",
       "and a word processor.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.query_engine import RetryQueryEngine\n",
    "from llama_index.evaluation import RelevancyEvaluator\n",
    "\n",
    "query_response_evaluator = RelevancyEvaluator()\n",
    "retry_query_engine = RetryQueryEngine(\n",
    "    base_query_engine, query_response_evaluator\n",
    ")\n",
    "retry_response = retry_query_engine.query(query)\n",
    "rprint(retry_response.response)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retry Source Query Engine\n",
    "The Source Retry modifies the query source nodes by filtering the existing source nodes for the query based on llm node evaluation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The author, growing up, worked on writing and programming. They wrote short stories and tried writing programs on \n",
       "an IBM <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1401</span> computer. They later got a microcomputer and started programming more extensively, writing simple games\n",
       "and a word processor.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The author, growing up, worked on writing and programming. They wrote short stories and tried writing programs on \n",
       "an IBM \u001b[1;36m1401\u001b[0m computer. They later got a microcomputer and started programming more extensively, writing simple games\n",
       "and a word processor.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.query_engine import RetrySourceQueryEngine\n",
    "\n",
    "retry_source_query_engine = RetrySourceQueryEngine(\n",
    "    base_query_engine, query_response_evaluator\n",
    ")\n",
    "retry_source_response = retry_source_query_engine.query(query)\n",
    "rprint(retry_source_response.response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retry Guideline Query Engine\n",
    "This module tries to use guidelines to direct the evaluator’s behavior. You can customize your own guidelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.evaluation.guideline import (\n",
    "    GuidelineEvaluator,\n",
    "    DEFAULT_GUIDELINES,\n",
    ")\n",
    "from llama_index.response.schema import Response\n",
    "from llama_index.indices.query.query_transform.feedback_transform import (\n",
    "    FeedbackQueryTransformation,\n",
    ")\n",
    "from llama_index.query_engine.retry_query_engine import (\n",
    "    RetryGuidelineQueryEngine,\n",
    ")\n",
    "\n",
    "# Guideline eval\n",
    "guideline_eval = GuidelineEvaluator(\n",
    "    guidelines=DEFAULT_GUIDELINES\n",
    "    + \"\\nThe response should not be overly long.\\n\"\n",
    "    \"The response should try to summarize where possible.\\n\"\n",
    ")  # just for example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s look like what happens under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Guideline eval evaluation result: The response partially answers the query by mentioning that the author worked on \n",
       "writing and programming. However, it lacks specific details and statistics. For example, it would be helpful to \n",
       "know how many short stories the author wrote or how many programs they attempted on the IBM <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1401</span> computer. \n",
       "Additionally, the response could be more concise by summarizing the information provided.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Guideline eval evaluation result: The response partially answers the query by mentioning that the author worked on \n",
       "writing and programming. However, it lacks specific details and statistics. For example, it would be helpful to \n",
       "know how many short stories the author wrote or how many programs they attempted on the IBM \u001b[1;36m1401\u001b[0m computer. \n",
       "Additionally, the response could be more concise by summarizing the information provided.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Transformed query: Here is a previous bad answer.\n",
       "The author, growing up, worked on writing and programming. They wrote short stories and tried writing programs on \n",
       "an IBM <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1401</span> computer. They later got a microcomputer and started programming more extensively, writing simple games\n",
       "and a word processor.\n",
       "Here is some feedback from the evaluator about the response given.\n",
       "The response partially answers the query by mentioning that the author worked on writing and programming. However, \n",
       "it lacks specific details and statistics. For example, it would be helpful to know how many short stories the \n",
       "author wrote or how many programs they attempted on the IBM <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1401</span> computer. Additionally, the response could be more\n",
       "concise by summarizing the information provided.\n",
       "Now answer the question.\n",
       "What were the author's interests and activities during their childhood and adolescence?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Transformed query: Here is a previous bad answer.\n",
       "The author, growing up, worked on writing and programming. They wrote short stories and tried writing programs on \n",
       "an IBM \u001b[1;36m1401\u001b[0m computer. They later got a microcomputer and started programming more extensively, writing simple games\n",
       "and a word processor.\n",
       "Here is some feedback from the evaluator about the response given.\n",
       "The response partially answers the query by mentioning that the author worked on writing and programming. However, \n",
       "it lacks specific details and statistics. For example, it would be helpful to know how many short stories the \n",
       "author wrote or how many programs they attempted on the IBM \u001b[1;36m1401\u001b[0m computer. Additionally, the response could be more\n",
       "concise by summarizing the information provided.\n",
       "Now answer the question.\n",
       "What were the author's interests and activities during their childhood and adolescence?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "typed_response = (\n",
    "    response if isinstance(response, Response) else response.get_response()\n",
    ")\n",
    "eval = guideline_eval.evaluate_response(query, typed_response)\n",
    "rprint(f\"Guideline eval evaluation result: {eval.feedback}\")\n",
    "\n",
    "feedback_query_transform = FeedbackQueryTransformation(resynthesize_query=True)\n",
    "transformed_query = feedback_query_transform.run(query, {\"evaluation\": eval})\n",
    "rprint(f\"Transformed query: {transformed_query.query_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The author's activities growing up included writing short stories and attempting to write programs on an IBM <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1401</span> \n",
       "computer. They later got a microcomputer and started programming more extensively, writing simple games and a word \n",
       "processor.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The author's activities growing up included writing short stories and attempting to write programs on an IBM \u001b[1;36m1401\u001b[0m \n",
       "computer. They later got a microcomputer and started programming more extensively, writing simple games and a word \n",
       "processor.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "retry_guideline_query_engine = RetryGuidelineQueryEngine(\n",
    "    base_query_engine, guideline_eval, resynthesize_query=True\n",
    ")\n",
    "retry_guideline_response = retry_guideline_query_engine.query(query)\n",
    "rprint(retry_guideline_response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
